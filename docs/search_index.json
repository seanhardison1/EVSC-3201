[
["stream-lab-3-week-of-410.html", "4 Stream Lab 3 (week of 4/10) 4.1 Hypothesis testing", " 4 Stream Lab 3 (week of 4/10) 4.1 Hypothesis testing The goal of the text and figures below is to describe the t test in a visually intuitive way, and was mostly derived from Zar (1984). Further information and another example are provided in your lab manuals on page 36. Hypothesis testing is all about drawing inferences about a broader population given a representative sample. A common approach to hypothesis testing involves comparing the means of two samples. For example, consider an experiment where nitrogen fertilizer was added to the soils of 40 randomly selected plants, with 40 other plants not recieving the nutrient treatment. The heights of each plant were measured after two weeks. The results of the experiment are shown in Figure 4.1. In this experiment, our null hypothesis (\\(H_0\\)) is that there is no difference in mean height between the plants recieving nutrient and no-nutrient treatments. We can test this hypothesis using a two sample t test, which is designed to infer differences in two populations being sampled. Figure 4.1: Histograms showing the heights of two groups of plants after two weeks of growth. The orange histogram reflects those plants that recieved a nitrogen treatment and the purple histogram shows the plants that did not. 4.1.1 The t statistic Before we jump into the two-sample t test, let’s explore some concepts. First consider the mean height of the no nitrogen sample: 10.3 cm. Next, say we found a value in the literature suggesting that the mean height of all plants of this species was 10 cm. Is the mean of this sample significantly different from the established value? This leaves us with the null hypothesis \\((H_0)\\) that there is no difference between the population mean \\((\\mu)\\) of 10 cm and our sample mean \\((\\bar{X})\\) of 10.3 cm \\((H_0: \\mu = \\bar{X})\\). To test this hypothesis, we start with the idea that the mean of our sample is only one of many possible means from samples of size 40 that could have been drawn at random from the population. Given the population mean of 10 cm \\((\\mu = 10\\;\\textrm{cm})\\), we can estimate how unlikely our sample mean is by calculating a t statistic: \\[t = \\frac{\\bar{X}-\\mu}{s_{\\bar{X}}} ,\\] where \\(\\bar{X}\\) is the sample mean, \\(\\mu\\) is hypothesized population mean, and \\(s_{\\bar{X}}\\) is the standard deviation of the sample. If our sample mean also equals 10, then \\(t = 0\\). If we resampled the population a thousand more times, calculated the t statistic for each sample mean, and plotted the histogram of all t statistics, the shape of the histogram would resemble the line in Figure 4.2. Figure 4.2: The t distribution, describing all possible sample means for n = 40. This t distribution is a probability distribution. Figure 4.2 describes the distribution of all possible mean values for a given sample size, which is known as the t distribution. The shape of the distribution changes according to the degrees of freedom \\((v)\\), which is equal to \\(n - 1\\). Therefore, our sample has \\(40-1 = 39\\) degrees of freedom. As sample size increases, the “tails” of the distribution shrink (Fig. 4.3), reflecting a greater probability of capturing the population mean in your sample. Figure 4.3: The t distribution with a range of degrees of freedom \\((v)\\). Note how the “tails” become larger when \\(v\\) is small. Some sample means are more likely than others. In this example, given the null hypothesis of the population mean being equal to 10 \\((H_0: \\mu = 10)\\), the probability of a sample mean being less than 7.6 cm is less than 2.5%, and the probability of a sample mean being greater than 12.4 cm is less than 2.5%. Therefore, the probability of a sample mean as extreme or more extreme than either value is less than 5%, or 0.05 (Fig. 4.4). Figure 4.4: The t distribution is centered around t = 0. However, we can contextualize the distribution within our example by adding the hypothesized population mean to t \\((t + 10\\;\\textrm{cm})\\). 4.1.2 The two-sample t test It turns out that if two populations have equal variances (the “spread” of the data) and are normally distributed, then the ratio of the difference in means \\((\\bar{X_1} - \\bar{X_2})\\) to the standard error of the difference between the sample means \\((s_{\\bar{X_1} - \\bar{X_2}})\\) is t distributed. The t statistic for a two-sample t test: \\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{s_{\\bar{X_1} - \\bar{X_2}}}\\] Therefore, when the above t statistic is large, it becomes unlikely that two samples were drawn from the same population, and it follows that each t statistic is associated with a probability (\\(P\\)), just like in our previous example. If \\(P\\) &lt; 0.05, then we can reject the null hypothesis of no difference between the means of our two samples. This P value is equivalent to the probability of the t statistic occurring by chance alone upon repeated sampling given that the null hypothesis is true. When we reject a null hypothesis based on P &lt; 0.05 using a two-sample t test, it means that the probability of seeing differences as larger or larger than what we identified is less than 5% if the samples were drawn from the same population. 4.1.3 t tests in R and Excel 4.1.3.1 R Here I’ll implement the two-sample t test as described above for the plant-nutrient example. In R, two-sample t tests are straightforward once the data are in the correct format. # first read in data, as practiced in the Forest Lab. df &lt;- read.csv(file = &quot;/users/seanhardison/documents/git/EVSC-3201/data/nutrient_example.csv&quot;) # view the first ten rows of data. head(df) ## no_nitrogen nitrogen_added X X.1 X.2 X.3 X.4 X.5 X.6 X.7 X.8 X.9 X.10 X.11 ## 1 9.338150 12.56883 NA NA NA NA NA NA NA ## 2 11.718954 13.38245 NA NA NA NA NA NA NA ## 3 12.121667 13.04113 NA NA NA NA NA NA NA ## 4 11.497154 12.94078 NA NA NA NA NA NA NA ## 5 9.963859 11.70358 NA NA NA NA NA NA NA ## 6 11.231945 10.86302 NA NA NA NA NA NA NA # do the t test comparing means between nutrient treatments t.test(df$no_nitrogen, df$nitrogen_added) ## ## Welch Two Sample t-test ## ## data: df$no_nitrogen and df$nitrogen_added ## t = -12.759, df = 77.952, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.920589 -2.132171 ## sample estimates: ## mean of x mean of y ## 10.33504 12.86142 The results show that \\(t = -12.79\\) and \\(P &lt; 0.0001\\). Therefore, we can reject the null hypothesis that there was no effect of nitrogen treatment, lending support to the alternative hypothesis that nitrogen is beneficial for plant growth. 4.1.3.2 Excel The process in Excel is just as quick and easy as in R. Once your spreadsheet is open, select the Data Analysis tab Next, select t-Test: Two-Sample Assuming Equal Variances Select Variable 1 Range and highlight the first column you want to compare Select Variable 2 Range and highlight the second column you want to compare Select OK 4.1.4 What do I report? When referring to a t test in the text, you should report the t statistic, degrees of freedom, and P value. When presenting results of a t test, refer to Table 2 on page 39 of your lab manual. 4.1.5 Assignments This week’s assignment is to write the results and discussion sections for your stream lab report. Complete instructions are available on pages 40-41 of your lab manual. The deadline for this assignment is Friday, April 10th at 2 PM. References "]
]
